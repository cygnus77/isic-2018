{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_resnet import Net\n",
    "\n",
    "net = Net()\n",
    "net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "\n",
    "train_loader, val_loader = dataset.create_loaders(val_percent = 20, batch_size = 10)\n",
    "\n",
    "print('training_size: %d, validation_size:%d' % (len(train_loader),len(val_loader)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[0:4], nrow=4,padding=20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    return (2. * intersection + 1.) / (torch.sum(y_true) + torch.sum(y_pred) + 1.)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    return (intersection + 1.) / (torch.sum(y_true) + torch.sum(y_pred) - intersection + 1.)\n",
    "\n",
    "def falsepos(y_true, y_pred):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    return torch.sum(y_pred) - intersection\n",
    "\n",
    "def falseneg(y_true, y_pred):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    return torch.sum(y_true) - intersection\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    return intersection / (torch.sum(y_pred) + 1.)\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    return intersection / (torch.sum(y_true) + 1.)\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    presci = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2*(presci * rec)/(presci + rec)\n",
    "\n",
    "def weighted_fscore_loss(prew=1, recw=1):\n",
    "    def fscore_loss(y_true, y_pred):\n",
    "        presci = precision(y_true, y_pred)\n",
    "        rec = recall(y_true, y_pred)\n",
    "        return -(prew+recw)*(presci * rec)/(prew*presci + recw*rec)\n",
    "    return fscore_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import Visualization\n",
    "\n",
    "learning_rate = 1e-5\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "iou_vis = Visualization('IOU / Dice Coeff.')\n",
    "fpfn_vis = Visualization('False Positive / False Negative')\n",
    "fscore_vis = Visualization('Precision, Recall, F-Score')\n",
    "loss_vis = Visualization('Mean loss')\n",
    "\n",
    "measures = {\n",
    "    'dice_coeff': (dice_coef, iou_vis), \n",
    "    'iou': (iou, iou_vis), \n",
    "    'fp': (falsepos, fpfn_vis), \n",
    "    'fn': (falseneg, fpfn_vis), \n",
    "    'precision': (precision, fscore_vis), \n",
    "    'recall': (recall, fscore_vis), \n",
    "    'fscore': (fscore, fscore_vis) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "\n",
    "measurement_log = []\n",
    "fscores = [(2,1)] * 5 + [(1.5,1)]*5 + [(1,1)]*5 + [(1,1.5)]*5 + [(1,2)]*5\n",
    "frozen = [16]*25\n",
    "# fscores = [(2,1)] * 5 + [(1.5,1)]*5 + [(1,1)]*5 + [(1,1.5)]*5 + [(1,2)]*5\n",
    "# frozen = [9] * 25\n",
    "\n",
    "for epoch in range(25):\n",
    "    net.freeze(frozen[epoch])\n",
    "    measurements = train.fit(net, train_loader, val_loader, weighted_fscore_loss(*(fscores[epoch])), optimizer, lrscheduler, measures, epoch, loss_vis)\n",
    "    measurement_log.append(measurements)\n",
    "    print(\"Epoch: %d: \" % epoch, end='')\n",
    "    for k,v in measurements.items():\n",
    "        print(\" {}:{:.5f}\".format(k,v), end=',')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "timestamp = time.strftime('%m%d%H%M')\n",
    "os.mkdir('./output-resnet_%s'%timestamp)\n",
    "\n",
    "# write out weights\n",
    "torch.save(net.state_dict(), './output-resnet_%s/ultrasound.pth' % timestamp)\n",
    "\n",
    "# write out log\n",
    "with open('./output-resnet_%s/info.txt' % timestamp, 'w') as f:\n",
    "    f.write('%s\\n' % time.strftime('%m-%d %H:%M'))\n",
    "    f.write('optimizer: %s\\n' % type(optimizer).__name__)\n",
    "    f.write('scheduler: %s\\n' % type(lrscheduler).__name__)\n",
    "    f.write('learning_rate: %.6f\\n' % learning_rate)\n",
    "    f.write('\\n')\n",
    "    \n",
    "with open('./output-resnet_%s/measurements.txt' % timestamp, 'w') as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerow([\"Epoch\"] + list(measurements.keys()))\n",
    "    for epoch,measurement in enumerate(measurement_log):\n",
    "        wr.writerow([epoch] + list(measurement.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HT = 224\n",
    "IMAGE_WD = 224\n",
    "\n",
    "dataiter = iter(val_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.cuda()\n",
    "output = net(images)\n",
    "\n",
    "\n",
    "for idx in range(10):\n",
    "    x, y, label = images[idx], output[idx], labels[idx]\n",
    "    \n",
    "    y = y.reshape(IMAGE_HT, IMAGE_WD).cpu().detach().numpy()\n",
    "    label = label.reshape(IMAGE_HT, IMAGE_WD).cpu().detach().numpy()\n",
    "\n",
    "    # convert image to HSV for annotations\n",
    "    img = x.cpu().detach().numpy()\n",
    "    img = (img + 1) * 127\n",
    "    img = img.astype(np.uint8)\n",
    "    img = np.dstack((img[0,:,:], img[1,:,:], img[2,:,:]))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # apply prediction and label markings\n",
    "    h = img[:,:,0]\n",
    "    s = img[:,:,1]\n",
    "    h[y > .75] += 50 # GREEN\n",
    "    s[y > .75] = 250\n",
    "    h[label > .75] += 100 # BLUE\n",
    "    s[label > .75] = 250\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    cv2.imwrite('./output_%s/%d.jpg'%(timestamp,idx), img)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-1.0)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
